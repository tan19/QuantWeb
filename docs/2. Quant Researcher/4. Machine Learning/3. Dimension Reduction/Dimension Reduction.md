# Dimension Reduction

\chapter{Clustering and Dimension Reduction}
\minitoc

\section{K-Means}
\begin{question}{Why K-Means has to use Euclidean distance?}{$\star$}{K-Means}
Why K-Means has to use Euclidean distance?
\end{question}
\begin{answer}{Why K-Means has to use Euclidean distance?}
The way k-means is constructed is not based on distances.
\url{https://stats.stackexchange.com/questions/81481/why-does-k-means-clustering-algorithm-use-only-euclidean-distance-metric}
\end{answer}





\subsubsection{Clustering and the Dirichlet process}
\subsubsection{Finite mixture models}
The basic assumption of a clustering problem is that each observation $\y_i$ belongs to a single cluster $k \in \{1,\cdots, K\}$, which has a cluster distribution
\begin{align}
P_k(\y_i | z_i = k)
\end{align}
where we have defined a latent variable $z_i$, indicating the cluster assignment of observation $\y_i$. Note that under the Bayesian framework, the latent variable $z_i$ itself has a distribution
\begin{align}
p_k^i \equiv P(z_i = k)
\end{align}

The marginal distribution of the observation $\y_i$ is then
\begin{align}
P(\y_i) = \sum_{k=1}^K P(z_i = k) P_k(\y_i | z_i = k)
\end{align}
A model of this form is called a {\em{finite mixture model}}.

\subsubsection{Bayesian mixture models}
Suppose we know there are $K$ clusters, we first sample the cluster parameters from some base measure:
\begin{align}
\btheta_1, \dots, \btheta_K \sim_{iid} G(\bbeta)
\end{align}
We then independently sample the latent cluster assignment vectors and the actual observations:
\begin{align}
(p_1^i, \dots, p_K^i) &\sim \text{Dirichlet}_K(\alpha)\\
z_i &\sim \text{Categorical}(p_1^i, \dots, p_K^i)\\
\y_i &\sim P_k(\y_i | \btheta_k, z_i = k)
\end{align}

\subsubsection{Dirichlet Process}
\deff{
	If $\alpha > 0$ and if $G$ is a probability measure on $\Omega_\phi$, the random discrete probability measure $\Theta$ generated by
	\begin{align}
	V_1, V_2, \dots \sim_{iid} \text{Beta}(1,\alpha)\\
	C_k = V_k\prod_{j=1}^{k-1}(1-V_k)\\
	\Phi_1, \Phi_2, \dots \sim_{iid} G
	\end{align}
	is called a {\em{Dirichlet process (DP)}} with base measure $G$ and concentration $\alpha$, and denote its law by $\text{DP}(\alpha, G)$.
}

\subsubsection{Glossary}
\url{http://alumni.media.mit.edu/~tpminka/statlearn/glossary/}






